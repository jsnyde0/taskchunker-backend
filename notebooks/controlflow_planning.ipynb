{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Agentic Planning with ControlFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "import controlflow as cf\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dc0300acc248afa79ba1777f1bfb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Research and Study GenAI**:\n",
      "    - Understand what generative AI (genAI) encompasses.\n",
      "    - Identify key skills and concepts required for a GenAI engineer.\n",
      "\n",
      "2. **Skill Acquisition**:\n",
      "    - Learn programming languages commonly used in AI, such as Python.\n",
      "    - Study machine learning and deep learning fundamentals.\n",
      "    - Gain expertise in frameworks like TensorFlow and PyTorch.\n",
      "    - Develop understanding in AI model development and deployment.\n",
      "\n",
      "3. **Build a Portfolio**:\n",
      "    - Work on GenAI projects or simulations, such as creating generative models or AI tools.\n",
      "    - Document projects, detailing the problem-solving process and outcomes.\n",
      "    - Publish projects on platforms like GitHub for visibility.\n",
      "\n",
      "4. **Networking and Community Involvement**:\n",
      "    - Join GenAI and AI-related meetups, forums, or online communities.\n",
      "    - Attend webinars, workshops, and conferences.\n",
      "    - Connect with current GenAI professionals on LinkedIn or other platforms.\n",
      "\n",
      "5. **Apply for Jobs**:\n",
      "    - Update resume to highlight relevant skills and projects.\n",
      "    - Tailor cover letters for GenAI positions.\n",
      "    - Apply for entry-level and internships in genAI roles or companies.\n",
      "\n",
      "6. **Prepare for Interviews**:\n",
      "    - Practice common interview questions for GenAI roles.\n",
      "    - Develop a thorough understanding of previous projects.\n",
      "    - Prepare to demonstrate problem-solving abilities in technical assessments or tests.\n"
     ]
    }
   ],
   "source": [
    "reply = cf.run(\n",
    "    \"Chunk a project into smaller tasks\",\n",
    "    context=dict(project=\"Get a job as a genAI engineer\"),\n",
    ")\n",
    "\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9479a209aa4a46f78fec458f2a7bea0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Update resume\n",
      "   1.1 Gather current job experiences\n",
      "   1.2 Update skills and educational background\n",
      "   1.3 Tailor resume for GenAI roles\n",
      "   1.4 Format and proofread resume\n",
      "2. Build portfolio\n",
      "   2.1 Identify projects relevant to GenAI\n",
      "   2.2 Create or refine case studies\n",
      "   2.3 Upload projects to a personal website or GitHub\n",
      "3. Networking\n",
      "   3.1 Join GenAI communities online\n",
      "   3.2 Attend industry conferences and meetups\n",
      "   3.3 Reach out to professionals in the field\n",
      "4. Job applications\n",
      "   4.1 Search for job openings\n",
      "   4.2 Apply to positions with tailored resumes\n",
      "   4.3 Follow up on applications\n",
      "5. Prepare for interviews\n",
      "   5.1 Research common interview questions in GenAI\n",
      "   5.2 Conduct mock interviews\n",
      "   5.3 Develop a personal pitch for interviews\n"
     ]
    }
   ],
   "source": [
    "# Create a specialized agent\n",
    "chunker = cf.Agent(\n",
    "    name=\"Project Chunker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=\"You are a project planning expert using the Getting Things Done \\\n",
    "        (GTD) methodology. When given a project or task, chunk it down into a \\\n",
    "        hierarchical tree of subtasks.\",\n",
    ")\n",
    "\n",
    "\n",
    "# Set up a ControlFlow task to classify emails\n",
    "tasks = cf.run(\n",
    "    \"Chunk the project into a hierarchical task tree\",\n",
    "    # result_type=TaskList,\n",
    "    agents=[chunker],\n",
    "    context=dict(project=\"Get a job as a genAI engineer\"),\n",
    ")\n",
    "\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b544ef9daf0843098901dccf57e1a391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks=[ChunkedTask(id='1', parent_id=None, title='Get a job as a genAI engineer', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.1', parent_id='1', title='Update resume', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.1.1', parent_id='1.1', title='Review current resume', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.1.2', parent_id='1.1', title='Add relevant projects and experiences', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.1.3', parent_id='1.1', title='Tailor resume for specific job applications', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.2', parent_id='1', title='Build portfolio', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.2.1', parent_id='1.2', title='Select projects to showcase', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.2.2', parent_id='1.2', title='Create project descriptions', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.2.3', parent_id='1.2', title='Design portfolio website', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.3', parent_id='1', title='Networking', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.3.1', parent_id='1.3', title='Connect with professionals in the field', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.3.2', parent_id='1.3', title='Attend industry events', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.3.3', parent_id='1.3', title='Join relevant online communities', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.4', parent_id='1', title='Apply for jobs', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.4.1', parent_id='1.4', title='Identify job openings', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.4.2', parent_id='1.4', title='Submit applications', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.4.3', parent_id='1.4', title='Prepare for interviews', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.5', parent_id='1', title='Follow up', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.5.1', parent_id='1.5', title='Check application status', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.5.2', parent_id='1.5', title='Reach out to contacts for updates', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087)), ChunkedTask(id='1.5.3', parent_id='1.5', title='Thank interviewers', created_at=datetime.datetime(2025, 2, 12, 16, 14, 47, 462087))]\n"
     ]
    }
   ],
   "source": [
    "# Create a specialized agent\n",
    "chunker = cf.Agent(\n",
    "    name=\"Project Chunker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=\"You are a project planning expert using the Getting Things Done \\\n",
    "        (GTD) methodology. When given a project or task, chunk it down into a \\\n",
    "        hierarchical tree of subtasks.\",\n",
    ")\n",
    "\n",
    "\n",
    "class ChunkedTask(BaseModel):\n",
    "    id: str = Field(description=\"Unique identifier for the task\")\n",
    "    parent_id: Optional[str] = Field(\n",
    "        None, description=\"ID of parent task, null if root\"\n",
    "    )\n",
    "    title: str = Field(description=\"Title that captures the task's action/outcome\")\n",
    "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks: List[\"ChunkedTask\"] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "# Set up a ControlFlow task to classify emails\n",
    "chunk_task = cf.Task(\n",
    "    objective=\"Chunk the project into a hierarchical task tree\",\n",
    "    result_type=TaskList,\n",
    "    agents=[chunker],\n",
    "    context=dict(project=\"Get a job as a genAI engineer\"),\n",
    ")\n",
    "\n",
    "tasks = chunk_task.run()\n",
    "\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent Solution\n",
    "The flow we're eying atm would be this:\n",
    "```\n",
    "A: input P -> B [find Ps without NA children]\n",
    "B -> C{Any found?}\n",
    "C -> |yes| D[generate children for these Ps]\n",
    "D -> E[Classify new children as P or NA]\n",
    "E -> D\n",
    "C -> |no| F[Check if each P's direct children achieve its outcome]\n",
    "F -> |Incomplete Ps| D\n",
    "F -> |all complete| G[Final Task Tree]\n",
    "```\n",
    "\n",
    "But let's build towards this gradually.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_task_tree(tasks: TaskList, parent_id: str = \"1\", indent: int = 0):\n",
    "    \"\"\"Print tasks in a hierarchical tree format.\n",
    "\n",
    "    Args:\n",
    "        tasks: TaskList containing all tasks\n",
    "        parent_id: ID of parent task to start from (defaults to \"1\")\n",
    "        indent: Current indentation level\n",
    "    \"\"\"\n",
    "    # Find tasks with this parent\n",
    "    current_level = [t for t in tasks.tasks if t.parent_id == parent_id]\n",
    "\n",
    "    # Print each task at this level\n",
    "    for task in current_level:\n",
    "        print(\"    \" * indent + f\"- {task.title}\")\n",
    "        print_task_tree(tasks, task.id, indent + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V0.1.1 - 1 agent and 1 task to chunk a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskPNA(BaseModel):\n",
    "    id: str = Field(description=\"unique identifier for the task\")\n",
    "    title: str = Field(description=\"A short title/description of the task\")\n",
    "    parent_id: Optional[str] = Field(\n",
    "        None, description=\"ID of this task's parent task, null if root\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks: List[TaskPNA] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e0050a90a44dad9a5b68be363eb343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks=[TaskPNA(id='1', title='Get a job as a genAI engineer', parent_id=None), TaskPNA(id='1.1', title='Update resume to highlight GenAI skills', parent_id='1'), TaskPNA(id='1.2', title='Research job openings related to GenAI engineering', parent_id='1'), TaskPNA(id='1.3', title='Prepare for interviews by practicing common questions', parent_id='1'), TaskPNA(id='1.4', title='Network with professionals in the GenAI field', parent_id='1')]\n"
     ]
    }
   ],
   "source": [
    "# Create a specialized agent\n",
    "chunker_instructions = \"\"\"\n",
    "You are a Getting Things Done project management expert, specialized into\n",
    "subdividing big tasks into smaller ones.\n",
    "\"\"\"\n",
    "chunker = cf.Agent(\n",
    "    name=\"Project Chunker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=chunker_instructions,\n",
    ")\n",
    "\n",
    "\n",
    "@cf.flow\n",
    "def chunk_flow_v0_1_1(project: str):\n",
    "    # Initialize with root project\n",
    "    root_task_id = \"1\"\n",
    "    tasks = TaskList(tasks=[TaskPNA(id=root_task_id, title=project, parent_id=None)])\n",
    "\n",
    "    with cf.Task(\n",
    "        \"Generate hyrarchical task tree for this project\",\n",
    "        result_type=TaskList,\n",
    "        agents=[chunker],\n",
    "    ) as main_task:\n",
    "        new_tasks = cf.run(\n",
    "            \"\"\"\n",
    "            Break given task (with id {task_id}) into subtasks.\n",
    "            Ensure that any subtask saves the task_id of its parent task as its\n",
    "            parent_id.\n",
    "            Once you split the task into subtasks, mark this task as complete and\n",
    "            use the main task tool to mark that as complete.\n",
    "            \"\"\",\n",
    "            context=dict(\n",
    "                task_id=root_task_id,\n",
    "                tasks=tasks,\n",
    "            ),\n",
    "            agents=[chunker],\n",
    "            result_type=TaskList,\n",
    "            tools=[main_task.get_success_tool()],\n",
    "        )\n",
    "\n",
    "        tasks = TaskList(tasks=tasks.tasks + new_tasks.tasks)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "tasks = chunk_flow_v0_1_1(\"Get a job as a genAI engineer\")\n",
    "\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks=[TaskPNA(id='1', title='Get a job as a genAI engineer', parent_id=None), TaskPNA(id='1.1', title='Update resume to highlight GenAI skills', parent_id='1'), TaskPNA(id='1.2', title='Research job openings related to GenAI engineering', parent_id='1'), TaskPNA(id='1.3', title='Prepare for interviews by practicing common questions', parent_id='1'), TaskPNA(id='1.4', title='Network with professionals in the GenAI field', parent_id='1')]\n"
     ]
    }
   ],
   "source": [
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1: Get a job as a genAI engineer (parent: None)', '1.1: Update resume to highlight GenAI skills (parent: 1)', '1.2: Research job openings related to GenAI engineering (parent: 1)', '1.3: Prepare for interviews by practicing common questions (parent: 1)', '1.4: Network with professionals in the GenAI field (parent: 1)']\n"
     ]
    }
   ],
   "source": [
    "print([f\"{t.id}: {t.title} (parent: {t.parent_id})\" for t in tasks.tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Update resume to highlight GenAI skills\n",
      "- Research job openings related to GenAI engineering\n",
      "- Prepare for interviews by practicing common questions\n",
      "- Network with professionals in the GenAI field\n"
     ]
    }
   ],
   "source": [
    "print_task_tree(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V0.1.2 - converting task list to tree of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskNode(BaseModel):\n",
    "    id: str = Field(description=\"Unique identifier for the task\")\n",
    "    title: str = Field(description=\"Title/description of the task\")\n",
    "    subtasks: List[\"TaskNode\"] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "TaskNode.model_rebuild()\n",
    "\n",
    "\n",
    "# Result wrapper for ControlFlow\n",
    "class TaskResult(BaseModel):\n",
    "    task: TaskNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65934c3393054c339b392c11eb7d0ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='1' title='Get a job as a genAI engineer' subtasks=[TaskNode(id='1.1', title='Update resume and portfolio', subtasks=[]), TaskNode(id='1.2', title='Research job openings in AI engineering', subtasks=[]), TaskNode(id='1.3', title='Prepare for common interview questions', subtasks=[]), TaskNode(id='1.4', title='Network with professionals in the industry', subtasks=[]), TaskNode(id='1.5', title='Apply to selected job openings', subtasks=[])]\n"
     ]
    }
   ],
   "source": [
    "chunker_instructions = \"\"\"\n",
    "You are a Getting Things Done project management expert, specialized into\n",
    "subdividing big tasks into smaller ones.\n",
    "\"\"\"\n",
    "chunker = cf.Agent(\n",
    "    name=\"Project Chunker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=chunker_instructions,\n",
    ")\n",
    "\n",
    "\n",
    "@cf.flow\n",
    "def chunk_flow_v0_1_2(project: str):\n",
    "    # Initialize with root project\n",
    "    root_task_id = \"1\"\n",
    "    root_task = TaskNode(id=root_task_id, title=project)\n",
    "\n",
    "    with cf.Task(\n",
    "        \"Generate hyrarchical task tree for this project\",\n",
    "        result_type=TaskResult,\n",
    "        agents=[chunker],\n",
    "    ) as main_task:\n",
    "        new_tasks = cf.run(\n",
    "            \"\"\"\n",
    "            Break given task into subtasks.\n",
    "            Return a TaskResult containing a TaskNode with:\n",
    "            - The root task\n",
    "            - 3-5 subtasks in the subtasks list\n",
    "            Once you split the task into subtasks, mark this task as complete and\n",
    "            use the main task tool to mark that as complete.\n",
    "            \"\"\",\n",
    "            context=dict(\n",
    "                task=root_task,\n",
    "            ),\n",
    "            agents=[chunker],\n",
    "            result_type=TaskResult,\n",
    "            tools=[main_task.get_success_tool()],\n",
    "        )\n",
    "\n",
    "        # tasks = TaskList(tasks=tasks.tasks + new_tasks.tasks)\n",
    "\n",
    "    return new_tasks.task\n",
    "\n",
    "\n",
    "tasks = chunk_flow_v0_1_2(\"Get a job as a genAI engineer\")\n",
    "\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_task_nodes(task: TaskNode, indent: int = 0):\n",
    "    \"\"\"Print task tree recursively with nice formatting.\n",
    "\n",
    "    Args:\n",
    "        task: Task to print\n",
    "        indent: Current indentation level\n",
    "    \"\"\"\n",
    "    # Print current task with indentation\n",
    "    print(\"    \" * indent + f\"{task.id} {task.title}\")\n",
    "\n",
    "    # Recursively print subtasks\n",
    "    for subtask in task.subtasks:\n",
    "        print_task_nodes(subtask, indent + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Get a job as a genAI engineer\n",
      "    - Update resume and portfolio\n",
      "    - Research job openings in AI engineering\n",
      "    - Prepare for common interview questions\n",
      "    - Network with professionals in the industry\n",
      "    - Apply to selected job openings\n"
     ]
    }
   ],
   "source": [
    "print_task_nodes(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1.0 - multiple agents etc (WIP - not working)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up data models, agents, and tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskPNA(BaseModel):\n",
    "    id: str\n",
    "    title: str = Field(\n",
    "        description=\"\"\"\n",
    "        For Projects: The desired outcome state (e.g., \"garage cleaned and organized\")\n",
    "        For Next Actions: The concrete action (e.g., \"sweep garage floor\")\n",
    "    \"\"\"\n",
    "    )\n",
    "    parent_id: Optional[str] = Field(None, description=\"parent task ID, null if root\")\n",
    "    classification: Optional[Literal[\"Project\", \"Next Action\"]] = Field(\n",
    "        None, description=\"Whether this task is a Project or Next Action\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks: List[TaskPNA] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class TaskClassification(BaseModel):\n",
    "    task_id: str\n",
    "    classification: Literal[\"Project\", \"Next Action\"]\n",
    "\n",
    "\n",
    "# Agents\n",
    "chunker = cf.Agent(\n",
    "    name=\"Project Chunker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a Getting Things Done expert, specialized in subdividing \n",
    "        Projects into Next Actions or sub-Projects.\n",
    "        \n",
    "        When describing a Project, always phrase it as a completed outcome state \n",
    "        (e.g., \"kitchen fully renovated\", \"report completed and approved\").\n",
    "        \n",
    "        When describing a Next Action, always phrase it as a concrete physical action \n",
    "        (e.g., \"call contractor at 555-0123\", \"draft first section of report\").\n",
    "        \n",
    "        Each task description should be clear enough that someone else could understand \n",
    "        exactly what needs to be done or what outcome needs to be achieved.\"\"\",\n",
    ")\n",
    "\n",
    "reviewer = cf.Agent(\n",
    "    name=\"Task Reviewer\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a Getting Things Done expert, categorizing tasks as either \n",
    "        Projects or Next Actions.\n",
    "        \n",
    "        A Next Action:\n",
    "        - Is a single, physical action\n",
    "        - Can be done in one sitting\n",
    "        - Has no prerequisites\n",
    "        - Uses an action verb\n",
    "        - Is very specific (e.g., \"email John about budget\" vs \"contact John\")\n",
    "        \n",
    "        A Project:\n",
    "        - Requires multiple actions to complete\n",
    "        - Is described as a completed outcome\n",
    "        - Uses past tense to describe the desired state\n",
    "        - Will likely need planning or coordination\"\"\",\n",
    ")\n",
    "\n",
    "completeness_checker = cf.Agent(\n",
    "    name=\"Completeness Checker\",\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a Getting Things Done expert, specialized in verifying if a \n",
    "        set of subtasks is sufficient to achieve their parent task's outcome.\n",
    "        \n",
    "        For each Project, evaluate if its direct children (both Next Actions and \n",
    "        sub-Projects) collectively will achieve the Project's stated outcome.\n",
    "        \n",
    "        Example:\n",
    "        Project: \"garage cleaned and organized\"\n",
    "        Subtasks:\n",
    "        1. \"remove items from garage\"\n",
    "        2. \"sort items into keep/donate piles\"\n",
    "        3. \"sweep garage floor\"\n",
    "        \n",
    "        This is incomplete because it's missing:\n",
    "        - Disposing of non-kept items\n",
    "        - Organizing kept items back into garage\n",
    "        - Potentially cleaning walls/surfaces\"\"\",\n",
    ")\n",
    "\n",
    "# Tasks\n",
    "chunk_task = cf.Task(\n",
    "    objective=\"Generate child tasks for the given Project\",\n",
    "    result_type=TaskList,\n",
    "    agents=[chunker],\n",
    ")\n",
    "\n",
    "review_task = cf.Task(\n",
    "    objective=\"Classify each unclassified task as either a Project or Next Action\",\n",
    "    result_type=TaskList,\n",
    "    agents=[reviewer],\n",
    ")\n",
    "\n",
    "completeness_task = cf.Task(\n",
    "    objective=\"Check if the Project's direct children will achieve its outcome \\\n",
    "        and return the IDs of incomplete Projects as a list of strings.\",\n",
    "    result_type=List[str],  # IDs of incomplete Projects\n",
    "    agents=[completeness_checker],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_projects_without_nas(tasks: TaskList) -> List[TaskPNA]:\n",
    "    \"\"\"Find all Projects that don't have any Next Action children.\n",
    "\n",
    "    Args:\n",
    "        tasks: TaskList containing all tasks\n",
    "\n",
    "    Returns:\n",
    "        List of Project tasks that have no Next Action children\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for task in tasks.tasks:\n",
    "        if task.classification != \"Project\":\n",
    "            continue\n",
    "\n",
    "        # Find all children of this task\n",
    "        children = [t for t in tasks.tasks if t.parent_id == task.id]\n",
    "        # Check if any children are Next Actions\n",
    "        na_children = [c for c in children if c.classification == \"Next Action\"]\n",
    "\n",
    "        if not na_children:\n",
    "            result.append(task)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cf.flow\n",
    "def chunking_flow(project: str):\n",
    "    # Initialize with root project\n",
    "    tasks = TaskList(tasks=[TaskPNA(id=\"1\", title=project, classification=\"Project\")])\n",
    "\n",
    "    with cf.Task(\n",
    "        \"Break down project into a complete task tree\",\n",
    "        result_type=TaskList,\n",
    "        agents=[chunker, reviewer, completeness_checker],\n",
    "    ) as main_task:\n",
    "        while main_task.is_incomplete():\n",
    "            # Find Ps without NA children\n",
    "            projects_without_nas = find_projects_without_nas(tasks)\n",
    "\n",
    "            if projects_without_nas:\n",
    "                # Generate and classify new tasks\n",
    "                cf.run(\n",
    "                    \"Generate children for projects without Next Actions\",\n",
    "                    context=dict(\n",
    "                        parent_tasks=projects_without_nas, existing_tasks=tasks\n",
    "                    ),\n",
    "                    agents=[chunker],\n",
    "                    result_type=TaskList,\n",
    "                )\n",
    "\n",
    "                cf.run(\n",
    "                    \"Classify new tasks\",\n",
    "                    context=dict(tasks=tasks),\n",
    "                    agents=[reviewer],\n",
    "                    result_type=TaskList,\n",
    "                )\n",
    "            else:\n",
    "                # Check completeness\n",
    "                cf.run(\n",
    "                    \"Check if all Projects are complete\",\n",
    "                    context=dict(tasks=tasks),\n",
    "                    agents=[completeness_checker],\n",
    "                    result_type=List[str],\n",
    "                )\n",
    "\n",
    "    return main_task.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78830be3f72452386605d4dc25b4f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52cff29d2c04f5183c1ad1db3f3885b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96008eeb32ad4e8b8ee024d2f0fe7153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c831e5d81304c02ac4183d2f5937a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f018d5ac0914168a8edc4b03555b3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f80f1be841542b3a19e72b85e85f1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e8876e41604dd1aa7e83488506ebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c93bb76924b939beae7eec2c2c145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facd36cac2324c8db6ba2c8fa80210a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07351c73680f4ee495051c158a1f35d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec24f540d08e4fc68cfee38dd67bc06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c1915d48dd40c2a86764351b9ee16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb336e7406d4c4185a90b22dd287fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bacab902584f1e9f395f152d89bb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecfbd6f2f3a4a799a70799b36d3a998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee20dc408ebe4f438786a8fdda1d6c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74adfd27d7684299b03a62d3d9ba6001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272c38c52bbc49c49cdd2db0fb36634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71acb529764f4cd4931847733809725e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b593019355124ee29caea859495b40af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1467f05d3f2a4619bd8aa28c62503cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b7008cd58d4a34b9930533b2e8e811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a014b589e0ac4027af6363ee4e768152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85722dbb283d47b0a6e2b521e1f68534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891601b869c74259a732ec2e90557bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b37591eb17240478a8ddad3f03a8325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e35503fcf3b4c879e78aeff764fb326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ed7753db0a497daac3555b9bee931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fba7f943cf46a38b2dd779c72a9a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26c8e112f9b48dabb82a91eaa39bd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca233c2bd47e455dbe30a5dae96fedac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40ea1258345489a8477929ee1a58c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a26003d84654bf4a2a2ee6de4c331f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0fb1ec4bcb4069934384c46f6c1b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e408bf8c7443fcb7684cbcba58f32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.386 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Call LLM' - Crash detected! Execution was aborted by an interrupt signal.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.386 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Call LLM' - Crash detected! Execution was aborted by an interrupt signal.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.386 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Call LLM' - Finished in state <span style=\"color: #ff0000; text-decoration-color: #ff0000\">Crashed</span>('Execution was aborted by an interrupt signal.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.386 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Call LLM' - Finished in state \u001b[91mCrashed\u001b[0m('Execution was aborted by an interrupt signal.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.395 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Run agent orchestrator' - Crash detected! Execution was aborted by an interrupt signal.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.395 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Run agent orchestrator' - Crash detected! Execution was aborted by an interrupt signal.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.397 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Run agent orchestrator' - Finished in state <span style=\"color: #ff0000; text-decoration-color: #ff0000\">Crashed</span>('Execution was aborted by an interrupt signal.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.397 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Run agent orchestrator' - Finished in state \u001b[91mCrashed\u001b[0m('Execution was aborted by an interrupt signal.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.399 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'orthodox-mayfly'</span> - Crash detected! Execution was aborted by an interrupt signal.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.399 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'orthodox-mayfly'\u001b[0m - Crash detected! Execution was aborted by an interrupt signal.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:01.414 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'orthodox-mayfly'</span> - Finished in state <span style=\"color: #ff0000; text-decoration-color: #ff0000\">Crashed</span>('Execution was aborted by an interrupt signal.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:01.414 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'orthodox-mayfly'\u001b[0m - Finished in state \u001b[91mCrashed\u001b[0m('Execution was aborted by an interrupt signal.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cf\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mdebug_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mchunking_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGet a job as a genAI engineer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\flows.py:1648\u001b[0m, in \u001b[0;36mFlow.__call__\u001b[1;34m(self, return_state, wait_for, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misasync, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, parameters)\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_flow\n\u001b[1;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\flow_engine.py:1529\u001b[0m, in \u001b[0;36mrun_flow\u001b[1;34m(flow, flow_run, parameters, wait_for, return_type, error_logger, context)\u001b[0m\n\u001b[0;32m   1527\u001b[0m         ret_val \u001b[38;5;241m=\u001b[39m run_flow_async(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1529\u001b[0m         ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mrun_flow_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Abort, Pause):\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\flow_engine.py:1372\u001b[0m, in \u001b[0;36mrun_flow_sync\u001b[1;34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mrun_context():\n\u001b[1;32m-> 1372\u001b[0m             \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flow_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;28;01mif\u001b[39;00m return_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\flow_engine.py:784\u001b[0m, in \u001b[0;36mFlowRunEngine.call_flow_fn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_flow_fn()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_success(result)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\utilities\\callables.py:208\u001b[0m, in \u001b[0;36mcall_with_parameters\u001b[1;34m(fn, parameters)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m parameters_to_args_kwargs(fn, parameters)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\decorators.py:113\u001b[0m, in \u001b[0;36mflow.<locals>.wrapper\u001b[1;34m(*wrapper_args, **wrapper_kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m bound\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[0;32m    110\u001b[0m     create_flow_context(bound\u001b[38;5;241m.\u001b[39marguments),\n\u001b[0;32m    111\u001b[0m     controlflow\u001b[38;5;241m.\u001b[39minstructions(instructions),\n\u001b[0;32m    112\u001b[0m ):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mwrapper_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mwrapper_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mchunking_flow\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m     13\u001b[0m projects_without_nas \u001b[38;5;241m=\u001b[39m find_projects_without_nas(tasks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m projects_without_nas:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Generate and classify new tasks\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate children for projects without Next Actions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparent_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojects_without_nas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43magents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTaskList\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     cf\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassify new tasks\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(tasks\u001b[38;5;241m=\u001b[39mtasks),\n\u001b[0;32m     29\u001b[0m         agents\u001b[38;5;241m=\u001b[39m[reviewer],\n\u001b[0;32m     30\u001b[0m         result_type\u001b[38;5;241m=\u001b[39mTaskList,\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Check completeness\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\run.py:147\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(objective, turn_strategy, max_llm_calls, max_agent_turns, raise_on_failure, handlers, model_kwargs, run_until, stream, **task_kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mRun a single task.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m           e.g. StreamFilter.CONTENT | StreamFilter.AGENT_TOOLS\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m task \u001b[38;5;241m=\u001b[39m Task(objective\u001b[38;5;241m=\u001b[39mobjective, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtask_kwargs)\n\u001b[1;32m--> 147\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_on_failure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_failure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mturn_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturn_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_llm_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_llm_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_agent_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_agent_turns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandlers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandlers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_until\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_until\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\run.py:43\u001b[0m, in \u001b[0;36mrun_tasks\u001b[1;34m(tasks, instructions, flow, agent, turn_strategy, raise_on_failure, max_llm_calls, max_agent_turns, handlers, model_kwargs, run_until, stream)\u001b[0m\n\u001b[0;32m     34\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m Orchestrator(\n\u001b[0;32m     35\u001b[0m     tasks\u001b[38;5;241m=\u001b[39mtasks,\n\u001b[0;32m     36\u001b[0m     flow\u001b[38;5;241m=\u001b[39mflow,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     handlers\u001b[38;5;241m=\u001b[39mhandlers,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controlflow\u001b[38;5;241m.\u001b[39minstructions(instructions):\n\u001b[1;32m---> 43\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43morchestrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_llm_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_llm_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_agent_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_agent_turns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_until\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_until\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m# Convert True to ALL filter, otherwise use provided filter\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         stream_filter \u001b[38;5;241m=\u001b[39m Stream\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\orchestration\\orchestrator.py:371\u001b[0m, in \u001b[0;36mOrchestrator.run\u001b[1;34m(self, max_llm_calls, max_agent_turns, model_kwargs, run_until, stream)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run_context\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\task_engine.py:1456\u001b[0m, in \u001b[0;36mrun_generator_task_sync\u001b[1;34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m         gen_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m         \u001b[38;5;66;03m# link the current state to the result for dependency tracking\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m         \u001b[38;5;66;03m# TODO: this could grow the task_run_result\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;66;03m# dictionary in an unbounded way, so finding a\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m         \u001b[38;5;66;03m# way to periodically clean it up (using\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m         \u001b[38;5;66;03m# weakrefs or similar) would be good\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m         link_state_to_result(engine\u001b[38;5;241m.\u001b[39mstate, gen_result)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\orchestration\\orchestrator.py:280\u001b[0m, in \u001b[0;36mOrchestrator._run\u001b[1;34m(self, run_context, model_kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m turn_start\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Run turn and yield its events\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_agent_turn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\orchestration\\orchestrator.py:239\u001b[0m, in \u001b[0;36mOrchestrator._run_agent_turn\u001b[1;34m(self, run_context, model_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Run model and yield events\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx(orchestrator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\n\u001b[0;32m    246\u001b[0m run_context\u001b[38;5;241m.\u001b[39mllm_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\prefect\\task_engine.py:1456\u001b[0m, in \u001b[0;36mrun_generator_task_sync\u001b[1;34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m         gen_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m         \u001b[38;5;66;03m# link the current state to the result for dependency tracking\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m         \u001b[38;5;66;03m# TODO: this could grow the task_run_result\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;66;03m# dictionary in an unbounded way, so finding a\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m         \u001b[38;5;66;03m# way to periodically clean it up (using\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m         \u001b[38;5;66;03m# weakrefs or similar) would be good\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m         link_state_to_result(engine\u001b[38;5;241m.\u001b[39mstate, gen_result)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\controlflow\\agents\\agent.py:329\u001b[0m, in \u001b[0;36mAgent._run_model\u001b[1;34m(self, messages, tools, stream, model_kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    328\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5523\u001b[0m, in \u001b[0;36mRunnableBindingBase.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   5518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5519\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5520\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5521\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5522\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5523\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   5524\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5526\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5527\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:727\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m    726\u001b[0m     is_first_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\openai\\_streaming.py:46\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[1;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\openai\\_streaming.py:58\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[0;32m     56\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[1;32m---> 58\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[DONE]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\openai\\_streaming.py:50\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_bytes())\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\openai\\_streaming.py:280\u001b[0m, in \u001b[0;36mSSEDecoder.iter_bytes\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;49;00m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\openai\\_streaming.py:291\u001b[0m, in \u001b[0;36mSSEDecoder._iter_chunks\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 291\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpx\\_models.py:831\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpx\\_models.py:885\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    882\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 885\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpx\\_client.py:127\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpx\\_transports\\default.py:116\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\code\\taskchunker-backend\\notebooks\\.venv-notebooks\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.8-windows-x86_64-none\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.8-windows-x86_64-none\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cf.settings.debug_messages = True\n",
    "\n",
    "# chunking_flow(\"Get a job as a genAI engineer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
